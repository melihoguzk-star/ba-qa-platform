# Roadmap: Test Case XLSX Import (Tekli + Bulk)

> **Hedef:** Loodos Test Case Excel dokÃ¼manlarÄ±nÄ± (.xlsx) platforma import etmek.
> **Kaynak DokÃ¼man Analizi:** `Loodos_-_Kahve_DÃ¼nyasÄ±_Test_Case_Document_-_MOBÄ°L.xlsx`
> **Dosya Ä°statistikleri:** 59 sheet, 56 content sheet, ~2291 test case satÄ±rÄ±, 5 header varyantÄ±

---

## DokÃ¼man YapÄ± Analizi

### Genel YapÄ±
- Her `.xlsx` dosyasÄ±nda birden fazla **sheet** bulunur. Her sheet bir modÃ¼l/Ã¶zelliÄŸe ait test case'leri iÃ§erir.
- **Skip edilecek sheet'ler:** `Cover`, `Revision Changes`, `DATA` â€” bunlar meta/referans sheet'leridir, TC satÄ±rÄ± iÃ§ermez.
- **Content sheet'ler:** Geri kalan tÃ¼m sheet'ler (Ã¶rn: `Login&Register`, `Ana Sayfa`, `Sepet`, `Profilim`, vb.)

### Header VaryantlarÄ± (5 farklÄ± format tespit edildi)

TÃ¼m sheet'lerde ortak olan **Ã§ekirdek kolonlar** ÅŸunlardÄ±r (kolon adÄ± sheet'e gÃ¶re hafif deÄŸiÅŸebilir):

| Kavram | OlasÄ± Kolon AdlarÄ± | Zorunlu? |
|--------|-------------------|----------|
| TC ID | `TEST CASE ID` | HayÄ±r (bazÄ± sheet'lerde yok) |
| TC AdÄ± | `TESTCASE` / `TEST CASE` | âœ… Evet |
| AdÄ±mlar | `TEST STEPS` | âœ… Evet |
| Beklenen SonuÃ§ | `EXPECTED RESULT` | âœ… Evet |
| Priority | `PRIORTY` / `PRIORITY` | âœ… Evet (typo var!) |
| Channel | `CHANNEL` | âœ… Evet |
| TC Type | `TESTCASE TYPE` | âœ… Evet |
| User Type | `USER TYPE` | âœ… Evet |
| Test Area | `TEST AREA` | âœ… Evet |
| Test Scenario | `TEST SCENARIO` | âœ… Evet |
| Existence | `EXISTANCE` / `c` (typo) | Opsiyonel |
| Date | `DATE` | Opsiyonel |
| App Bundle | `APP BUNDLE` | Opsiyonel |
| BR ID | `BR ID` | Opsiyonel |
| TR ID | `TR ID` | Opsiyonel |
| Precondition | `PRECONDITION` | Opsiyonel |
| Test Data | `TEST DATA` | Opsiyonel |
| Postcondition | `POSTCONDITION` | Opsiyonel |
| Actual Result | `ACTUAL RESULT` | Opsiyonel |
| Status | `STATUS` | Opsiyonel |
| Regression | `REGRESSION CASE` | Opsiyonel |
| Main Business Case | `MAIN BUSINESS CASE` | Opsiyonel |
| Comments | `COMMENTS` | Opsiyonel |
| Created By | `CREATED BY` / `CREATED By` | Opsiyonel |
| Module | `MODULE` | Opsiyonel |
| Otomasyon | `OTOMASYON` | Opsiyonel |

### Header EÅŸleme Stratejisi (Ã‡OK Ã–NEMLÄ°)

**Kolon ismi tam eÅŸleÅŸme yerine fuzzy/alias matching kullanÄ±lmalÄ±:**

```python
COLUMN_ALIASES = {
    # Her canonical isim iÃ§in olasÄ± header deÄŸerleri (case-insensitive)
    "test_case_id": ["TEST CASE ID"],
    "testcase_name": ["TESTCASE", "TEST CASE"],  # Ä°KÄ° FARKLI AD!
    "test_steps": ["TEST STEPS"],
    "expected_result": ["EXPECTED RESULT"],
    "priority": ["PRIORTY", "PRIORITY"],  # TYPO VAR!
    "channel": ["CHANNEL"],
    "testcase_type": ["TESTCASE TYPE"],
    "user_type": ["USER TYPE"],
    "test_area": ["TEST AREA"],
    "test_scenario": ["TEST SCENARIO"],
    "existence": ["EXISTANCE", "EXISTANCE 2", "EXISTANCE 3", "EXISTANCE 4", "c"],
    "date": ["DATE"],
    "app_bundle": ["APP BUNDLE"],
    "br_id": ["BR ID"],
    "tr_id": ["TR ID"],
    "precondition": ["PRECONDITION"],
    "test_data": ["TEST DATA"],
    "postcondition": ["POSTCONDITION"],
    "actual_result": ["ACTUAL RESULT"],
    "status": ["STATUS"],
    "regression": ["REGRESSION CASE"],
    "main_business_case": ["MAIN BUSINESS CASE"],
    "comments": ["COMMENTS"],
    "created_by": ["CREATED BY", "CREATED By"],
    "module": ["MODULE"],
    "otomasyon": ["OTOMASYON"],
}
```

### Varyant DaÄŸÄ±lÄ±mÄ±

| Varyant | Sheet SayÄ±sÄ± | Fark |
|---------|-------------|------|
| 1 (Standart 17 kolon) | 47 | `TESTCASE` kullanÄ±lÄ±r |
| 2 (TEST CASE) | 5 | `TEST CASE` kullanÄ±lÄ±r (boÅŸluklu) |
| 3 (Extended) | 2 | `PRIORITY` (typo dÃ¼zeltilmiÅŸ) + `POSTCONDITION`, `STATUS`, `REGRESSION CASE`, `COMMENTS` |
| 4 (pinarÃœrÃ¼nDetay) | 1 | `EXISTANCE 2/3/4` ilave kolonlar, `TEST CASE ID` yok |
| 5 (Eksik kolon) | 1 | `EXPECTED RESULT` kolonu yok |

### Ã–zel Durumlar

1. **`Regresyon Seti` sheet'i** ayrÄ± bir yapÄ±ya sahip: `OTOMASYON` kolonu ekstra, 261 satÄ±r ile en bÃ¼yÃ¼k sheet.
2. **`pinarÃœrÃ¼nDetay` sheet'i** `TEST CASE ID` kolonu yok â€” `EXISTANCE 2/3/4` ile deÄŸiÅŸtirilmiÅŸ.
3. **`HazÄ±r AL - ÃœrÃ¼n SÄ±ralama Servis`** sheet'inde `EXPECTED RESULT` kolonu yok, yerine `TEST DATA` son kolon.
4. **`Ã‡ekirdek ile Ã¶deme`** sheet'inde ilk kolon header'Ä± `c` (lowercase, muhtemelen typo).
5. **BoÅŸ satÄ±rlar:** BazÄ± sheet'lerde 1000 satÄ±ra kadar boyut tanÄ±mlÄ± ama sadece birkaÃ§ satÄ±r dolu. BoÅŸ satÄ±r filtreleme ÅŸart.
6. **Merged cells:** BazÄ± sheet'lerde mevcut ama nadir. Parse sÄ±rasÄ±nda gÃ¶z ardÄ± edilebilir.
7. **Multiline cell content:** `TEST STEPS` kolonu genelde `1- AdÄ±m\n2- AdÄ±m\n3- AdÄ±m` formatÄ±nda multiline text iÃ§erir.

---

## Hedef JSON Schema

Her sheet parse edildiÄŸinde aÅŸaÄŸÄ±daki yapÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecek:

```json
{
  "sheet_name": "Login&Register",
  "test_cases": [
    {
      "test_case_id": "TC_LDS_KD_LOGIN_REGISTER_0001",
      "testcase_name": "Splash EkranÄ± UI KontrolÃ¼",
      "test_scenario": "Splash EkranÄ± KontrolÃ¼",
      "test_area": "Splash EkranÄ±",
      "priority": "MEDIUM",
      "channel": "MOBILE",
      "testcase_type": "UI",
      "user_type": "ALL",
      "test_steps": "1- Kahve dÃ¼nyasÄ± appi aÃ§Ä±lÄ±r.\n2- AÃ§Ä±lÄ±ÅŸ ekranÄ± kontrol edilir.",
      "expected_result": "KullanÄ±cÄ±nÄ±n app aÃ§Ä±lÄ±ÅŸÄ±nda tasarÄ±mda olan gÃ¶rÃ¼ntÃ¼leme...",
      "precondition": null,
      "test_data": null,
      "existence": "New",
      "date": "20.05.2024",
      "app_bundle": "Kahve DÃ¼nyasÄ±",
      "br_id": null,
      "tr_id": null,
      "postcondition": null,
      "created_by": null
    }
  ],
  "stats": {
    "total_rows": 38,
    "parsed_rows": 38,
    "skipped_rows": 0,
    "missing_required_fields": 0
  }
}
```

TÃ¼m dosya iÃ§in:

```json
{
  "file_name": "Loodos_Kahve_DÃ¼nyasÄ±_TC_MOBIL.xlsx",
  "doc_type": "loodos_test_case",
  "meta": {
    "project_name": "Kahve DÃ¼nyasÄ±",     // Cover sheet'ten
    "document_code": "LDS-PDQA-MT-KD-1", // Cover sheet'ten
    "created_by": "Salih Diken",          // Cover sheet'ten
    "create_date": "24.04.2024"           // Cover sheet'ten
  },
  "sheets": [ /* yukarÄ±daki sheet nesneleri */ ],
  "summary": {
    "total_sheets": 56,
    "total_test_cases": 2291,
    "by_priority": {"CRITICAL": 450, "HIGH": 620, "MEDIUM": 980, "LOW": 241},
    "by_channel": {"MOBILE": 1800, "WEB": 300, "API": 191},
    "by_type": {"Functional": 1400, "UI": 850, "Performance": 41}
  }
}
```

---

## Uygulama AdÄ±mlarÄ±

### AdÄ±m 1: TC Excel Reader (~2 saat)

**Dosya:** `pipeline/tc_xlsx_reader.py` (YENÄ°)

Bu modÃ¼l bir `.xlsx` dosyasÄ±nÄ± alÄ±p, sheet bazlÄ± raw data dÃ¶ndÃ¼rÃ¼r.

```python
"""
Loodos Test Case XLSX okuyucu.
openpyxl kullanarak sheet'leri okur, header'larÄ± eÅŸler, boÅŸ satÄ±rlarÄ± filtreler.
"""
import openpyxl
from typing import Optional

# TÃ¼m olasÄ± kolon adlarÄ± â†’ canonical isim eÅŸlemesi
COLUMN_ALIASES: dict[str, list[str]] = {
    "test_case_id": ["TEST CASE ID"],
    "testcase_name": ["TESTCASE", "TEST CASE"],
    "test_steps": ["TEST STEPS"],
    "expected_result": ["EXPECTED RESULT"],
    "priority": ["PRIORTY", "PRIORITY"],
    "channel": ["CHANNEL"],
    "testcase_type": ["TESTCASE TYPE"],
    "user_type": ["USER TYPE"],
    "test_area": ["TEST AREA"],
    "test_scenario": ["TEST SCENARIO"],
    "existence": ["EXISTANCE"],
    "date": ["DATE"],
    "app_bundle": ["APP BUNDLE"],
    "br_id": ["BR ID"],
    "tr_id": ["TR ID"],
    "precondition": ["PRECONDITION"],
    "test_data": ["TEST DATA"],
    "postcondition": ["POSTCONDITION"],
    "actual_result": ["ACTUAL RESULT"],
    "status": ["STATUS"],
    "regression": ["REGRESSION CASE"],
    "main_business_case": ["MAIN BUSINESS CASE"],
    "comments": ["COMMENTS"],
    "created_by": ["CREATED BY", "CREATED By"],
    "module": ["MODULE"],
    "otomasyon": ["OTOMASYON"],
}

SKIP_SHEETS = {"Cover", "Revision Changes", "DATA"}

# Bir satÄ±rÄ±n geÃ§erli TC olmasÄ± iÃ§in en az bu kanonik kolonlardan biri dolu olmalÄ±
REQUIRED_FOR_VALID_ROW = ["testcase_name", "test_steps", "expected_result"]


def read_tc_xlsx(file_content: bytes) -> dict:
    """
    Test Case XLSX dosyasÄ±nÄ± okur.
    
    Args:
        file_content: XLSX dosyasÄ±nÄ±n byte iÃ§eriÄŸi
        
    Returns:
        {
            "meta": {...},      # Cover sheet'ten Ã§Ä±karÄ±lan bilgiler
            "sheets": [...],    # Her content sheet'in raw datasÄ±
            "skip_sheets": [...] # Atlanan sheet isimleri
        }
    """
    # 1. Workbook aÃ§ (data_only=True â†’ formÃ¼ller yerine deÄŸerler)
    # 2. Cover sheet varsa meta bilgileri Ã§Ä±kar (_extract_cover_meta)
    # 3. Her content sheet iÃ§in:
    #    a. Header satÄ±rÄ±nÄ± bul (_find_header_row) â†’ ilk 5 satÄ±r iÃ§inde en az 3 dolu hÃ¼cre
    #    b. Header'larÄ± canonical isimlere eÅŸle (_map_headers)
    #    c. Data satÄ±rlarÄ±nÄ± oku, boÅŸ satÄ±rlarÄ± filtrele
    #    d. Her satÄ±rÄ± dict'e dÃ¶nÃ¼ÅŸtÃ¼r (canonical_name â†’ value)
    # 4. Return
    pass


def _extract_cover_meta(ws) -> dict:
    """
    Cover sheet'ten proje bilgilerini Ã§Ä±karÄ±r.
    Bilinen layout:
      C2: "Document Code"  â†’ D2: deÄŸer
      C3: "Project Name"   â†’ D3: deÄŸer
      C4: "Created By"     â†’ D4: deÄŸer
      C5: "Create Date"    â†’ D5: deÄŸer
    """
    pass


def _find_header_row(ws, max_search: int = 5) -> Optional[int]:
    """
    Ä°lk 5 satÄ±r iÃ§inde en az 3 dolu hÃ¼cre olan satÄ±rÄ± header olarak dÃ¶ndÃ¼rÃ¼r.
    """
    pass


def _map_headers(ws, header_row: int) -> dict[int, str]:
    """
    Header satÄ±rÄ±ndaki her hÃ¼creyi COLUMN_ALIASES kullanarak canonical isme eÅŸler.
    
    Returns: {col_index: canonical_name} 
    EÅŸleÅŸmeyen kolonlar: {col_index: "unknown_ORIGINAL_NAME"}
    """
    pass


def _is_valid_row(row_dict: dict) -> bool:
    """
    SatÄ±rÄ±n geÃ§erli bir TC olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    REQUIRED_FOR_VALID_ROW'daki alanlardan en az biri dolu olmalÄ±.
    Tamamen boÅŸ satÄ±rlarÄ± filtreler.
    """
    pass
```

**Dikkat edilecekler:**
- `openpyxl` ile aÃ§: `load_workbook(BytesIO(file_content), data_only=True)`
- Header eÅŸlemede case-insensitive karÅŸÄ±laÅŸtÄ±rma: `header.strip().upper()`
- Merged cell'lerde sadece sol Ã¼st hÃ¼cre deÄŸer iÃ§erir, diÄŸerleri `None`
- Date hÃ¼creleri `datetime` objesi olabilir â†’ string'e Ã§evir
- `test_steps` gibi multiline hÃ¼crelerde `\n` korunmalÄ±

---

### AdÄ±m 2: TC Parser & Normalizer (~2 saat)

**Dosya:** `pipeline/tc_xlsx_parser.py` (YENÄ°)

Reader'dan gelen raw data'yÄ± normalize eder ve hedef JSON schema'ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

```python
"""
Test Case Excel verilerini parse ve normalize eder.
Reader'dan gelen raw dict'leri, platform'un beklediÄŸi JSON yapÄ±sÄ±na Ã§evirir.
"""

PRIORITY_NORMALIZE = {
    "CRITICAL": "CRITICAL",
    "HIGH": "HIGH", 
    "MEDIUM": "MEDIUM",
    "LOW": "LOW",
    # OlasÄ± varyasyonlar
    "MED": "MEDIUM",
    "H": "HIGH",
    "L": "LOW",
    "C": "CRITICAL",
}

CHANNEL_NORMALIZE = {
    "MOBILE": "MOBILE",
    "WEB": "WEB",
    "API": "API",
    "ANDROID": "ANDROID",
    "IOS": "iOS",
}


class TCExcelParser:
    """Test Case Excel dokÃ¼manÄ± parser."""
    
    def __init__(self, raw_data: dict):
        """
        Args:
            raw_data: read_tc_xlsx() Ã§Ä±ktÄ±sÄ±
        """
        self.raw = raw_data
        self.warnings: list[str] = []
    
    def parse(self) -> dict:
        """
        TÃ¼m sheet'leri parse eder.
        
        Returns:
            {
                "file_name": str,
                "doc_type": "loodos_test_case",
                "meta": {...},
                "sheets": [
                    {
                        "sheet_name": str,
                        "test_cases": [...],
                        "stats": {...}
                    }
                ],
                "summary": {...},
                "warnings": [...]
            }
        """
        # 1. Her sheet'i _parse_sheet ile iÅŸle
        # 2. Summary hesapla (_calc_summary)
        # 3. Return
        pass
    
    def _parse_sheet(self, sheet_data: dict) -> dict:
        """
        Tek bir sheet'in raw satÄ±rlarÄ±nÄ± parse eder.
        
        Her satÄ±r iÃ§in:
        - Priority normalize et (PRIORTY typo â†’ PRIORITY)
        - Channel normalize et
        - test_steps'i temizle (baÅŸtaki/sondaki whitespace, empty line'lar)
        - BoÅŸ string'leri None'a Ã§evir
        - TC ID yoksa sheet adÄ± + satÄ±r numarasÄ±ndan Ã¼ret
        """
        pass
    
    def _normalize_priority(self, val: str) -> str:
        """PRIORTY/PRIORITY â†’ normalized value. Bilinmeyen deÄŸer â†’ 'UNKNOWN' + warning."""
        pass
    
    def _normalize_channel(self, val: str) -> str:
        """CHANNEL normalize. Bilinmeyen â†’ 'OTHER' + warning."""
        pass
    
    def _clean_test_steps(self, val: str) -> str:
        """
        Test adÄ±mlarÄ±nÄ± temizle:
        - Strip whitespace
        - Birden fazla boÅŸ satÄ±rÄ± teke indir
        - NumaralandÄ±rma formatÄ±nÄ± koru (1- AdÄ±m, 2- AdÄ±m)
        """
        pass
    
    def _generate_tc_id(self, sheet_name: str, row_idx: int) -> str:
        """TC ID yoksa Ã¼ret: TC_AUTO_{SHEET_NAME}_{ROW:04d}"""
        pass
    
    def _calc_summary(self, parsed_sheets: list) -> dict:
        """
        TÃ¼m sheet'lerdeki TC'leri toplayarak summary hesapla:
        - total_sheets, total_test_cases
        - by_priority: {CRITICAL: n, HIGH: n, ...}
        - by_channel: {MOBILE: n, WEB: n, ...}
        - by_type: {Functional: n, UI: n, ...}
        - by_test_area: {Login EkranÄ±: n, ...} (top 20)
        """
        pass
```

---

### AdÄ±m 3: Import Orchestrator GÃ¼ncelleme (~1.5 saat)

**Dosya:** `pipeline/docx_import_orchestrator.py` â†’ GÃœNCELLE (veya yeni `pipeline/import_orchestrator.py`)

Mevcut DOCX import orchestrator'a TC XLSX desteÄŸi ekle.

```python
def detect_document_type(file_content: bytes, file_name: str) -> dict:
    """
    Dosya tipini tespit et:
    
    1. UzantÄ± kontrolÃ¼:
       - .xlsx â†’ TC XLSX candidate
       - .docx â†’ BA DOCX candidate (mevcut logic)
    
    2. XLSX iÃ§in template detection:
       - Sheet isimlerinde "Cover", "Revision Changes" var mÄ±?
       - Header'larda "TEST CASE ID", "TESTCASE", "TEST STEPS" var mÄ±?
       - Evetse â†’ "loodos_test_case" template
       - HayÄ±rsa â†’ "generic_xlsx" (gelecekte desteklenecek)
    
    Returns:
        {
            "file_type": "xlsx" | "docx",
            "template": "loodos_test_case" | "loodos_ba_bullet" | "generic",
            "confidence": 0.0-1.0,
            "details": {...}
        }
    """
    pass
```

**Confidence hesaplama (XLSX):**
- Cover sheet var â†’ +0.2
- "TEST CASE ID" veya "TESTCASE" header var â†’ +0.3
- "PRIORTY" veya "PRIORITY" header var â†’ +0.2
- "TEST STEPS" + "EXPECTED RESULT" var â†’ +0.3
- Toplam â‰¥ 0.7 â†’ `loodos_test_case`

---

### AdÄ±m 4: UI - Import & Merge SayfasÄ± GÃ¼ncelleme (~2.5 saat)

**Dosya:** `pages/11_Import_Merge.py`

Mevcut "ğŸ“ Upload Word Document" bÃ¶lÃ¼mÃ¼nÃ¼ (satÄ±r 489-621) geniÅŸlet:

```python
# ===== YENÄ°: DOSYA UPLOAD BÃ–LÃœMÃœ =====

st.subheader("ğŸ“ DokÃ¼man YÃ¼kle")

uploaded_files = st.file_uploader(
    "BA (.docx) veya Test Case (.xlsx) dokÃ¼manlarÄ± yÃ¼kleyin",
    type=["docx", "xlsx"],
    accept_multiple_files=True,  # BULK IMPORT DESTEÄÄ°
    help="Birden fazla dosya seÃ§erek toplu import yapabilirsiniz."
)

if uploaded_files:
    # Her dosya iÃ§in process
    for uploaded_file in uploaded_files:
        with st.expander(f"ğŸ“„ {uploaded_file.name}", expanded=len(uploaded_files) == 1):
            file_bytes = uploaded_file.read()
            
            # 1. Tip tespiti
            doc_info = detect_document_type(file_bytes, uploaded_file.name)
            
            # 2. Tip'e gÃ¶re parse
            if doc_info["template"] == "loodos_test_case":
                _render_tc_import(file_bytes, uploaded_file.name, doc_info)
            elif doc_info["template"] in ("loodos_ba_bullet", "loodos_ba_table"):
                _render_ba_import(file_bytes, uploaded_file.name, doc_info)
            else:
                st.warning(f"Bilinmeyen dokÃ¼man formatÄ±: {doc_info}")


def _render_tc_import(file_bytes: bytes, file_name: str, doc_info: dict):
    """Test Case XLSX import UI."""
    
    # Parse
    raw = read_tc_xlsx(file_bytes)
    parser = TCExcelParser(raw)
    parsed = parser.parse()
    
    # === Metrics Bar ===
    cols = st.columns(4)
    cols[0].metric("ğŸ“‹ Sheet", parsed["summary"]["total_sheets"])
    cols[1].metric("ğŸ§ª Test Case", parsed["summary"]["total_test_cases"])
    cols[2].metric("âœ… Confidence", f"{doc_info['confidence']:.0%}")
    cols[3].metric("âš ï¸ Warning", len(parsed.get("warnings", [])))
    
    # === Warnings ===
    if parsed.get("warnings"):
        with st.expander("âš ï¸ UyarÄ±lar"):
            for w in parsed["warnings"]:
                st.warning(w)
    
    # === Preview Tabs ===
    tabs = st.tabs(["ğŸ“‹ Sheet BazlÄ±", "ğŸ“Š Ã–zet", "ğŸ” DetaylÄ± TC", "{} JSON"])
    
    with tabs[0]:  # Sheet BazlÄ±
        for sheet in parsed["sheets"]:
            with st.expander(f"{sheet['sheet_name']} ({sheet['stats']['total_rows']} TC)"):
                # DataFrame gÃ¶ster
                import pandas as pd
                df = pd.DataFrame(sheet["test_cases"])
                # Sadece Ã¶nemli kolonlarÄ± gÃ¶ster
                display_cols = ["test_case_id", "testcase_name", "priority", 
                               "channel", "testcase_type", "test_area"]
                existing = [c for c in display_cols if c in df.columns]
                st.dataframe(df[existing], use_container_width=True)
    
    with tabs[1]:  # Ã–zet
        summary = parsed["summary"]
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Priority DaÄŸÄ±lÄ±mÄ±:**")
            for k, v in summary.get("by_priority", {}).items():
                st.write(f"- {k}: {v}")
        with col2:
            st.write("**Channel DaÄŸÄ±lÄ±mÄ±:**")
            for k, v in summary.get("by_channel", {}).items():
                st.write(f"- {k}: {v}")
    
    with tabs[2]:  # DetaylÄ± TC
        # Arama + filtreleme
        search = st.text_input("ğŸ” TC Ara (ID veya isim)")
        # FiltrelenmiÅŸ TC listesi
        pass
    
    with tabs[3]:  # JSON
        st.json(parsed)
    
    # === Import Button ===
    if st.button(f"â¡ï¸ Import: {file_name}", type="primary"):
        # parsed datayÄ± veritabanÄ±na kaydet
        # Her TC'yi ayrÄ± dÃ¶kÃ¼man olarak veya sheet bazlÄ± kayÄ±t
        pass
```

**Bulk Import Flow:**
1. KullanÄ±cÄ± birden fazla `.xlsx` dosyasÄ± yÃ¼kler
2. Her dosya ayrÄ± bir `st.expander` iÃ§inde gÃ¶sterilir
3. Her dosya baÄŸÄ±msÄ±z olarak parse edilir ve preview gÃ¶sterilir
4. "TÃ¼mÃ¼nÃ¼ Import Et" butonu ile tÃ¼m dosyalar tek seferde import edilir
5. Tek dosya yÃ¼klendiÄŸinde otomatik olarak expander aÃ§Ä±k gelir

```python
# Bulk import bottom bar
if len(uploaded_files) > 1:
    st.divider()
    cols = st.columns([3, 1])
    cols[0].info(f"ğŸ“¦ {len(uploaded_files)} dosya yÃ¼klendi. Toplamda X test case.")
    if cols[1].button("ğŸš€ TÃ¼mÃ¼nÃ¼ Import Et", type="primary"):
        progress = st.progress(0)
        for i, uf in enumerate(uploaded_files):
            # import logic per file
            progress.progress((i + 1) / len(uploaded_files))
        st.success("âœ… TÃ¼m dosyalar import edildi!")
```

---

### AdÄ±m 5: VeritabanÄ± Entegrasyonu (~1.5 saat)

**Dosya:** `database/` altÄ±ndaki ilgili modÃ¼ller

TC import'un platform veritabanÄ±na nasÄ±l kaydedileceÄŸi:

```python
def save_tc_import(parsed_data: dict, source_file: str) -> dict:
    """
    Parse edilmiÅŸ TC verisini veritabanÄ±na kaydet.
    
    KayÄ±t stratejisi:
    1. Dosya bazlÄ± Ã¼st kayÄ±t oluÅŸtur (file_name, import_date, meta bilgiler)
    2. Her sheet iÃ§in sheet kaydÄ± oluÅŸtur
    3. Her TC satÄ±rÄ± ayrÄ± dokÃ¼man olarak kaydet
    4. ChromaDB'ye semantik arama iÃ§in embedding oluÅŸtur:
       - TC adÄ± + test scenario + test steps â†’ embedding text
    
    Duplicate detection:
    - test_case_id aynÄ± olan kayÄ±tlar varsa â†’ gÃ¼ncelle (upsert)
    - test_case_id yoksa â†’ yeni kayÄ±t
    
    Returns: {"imported": n, "updated": n, "skipped": n, "errors": [...]}
    """
    pass
```

---

### AdÄ±m 6: Test Suite (~1.5 saat)

**Dosyalar:**
- `tests/test_tc_xlsx_reader.py` (YENÄ°)
- `tests/test_tc_xlsx_parser.py` (YENÄ°)

```python
# tests/conftest.py - Test fixture ekle
@pytest.fixture
def sample_tc_xlsx():
    """Minimal TC XLSX fixture oluÅŸtur."""
    from openpyxl import Workbook
    
    wb = Workbook()
    
    # Cover sheet
    ws_cover = wb.active
    ws_cover.title = "Cover"
    ws_cover["C2"] = "Document Code"
    ws_cover["D2"] = "LDS-TEST-001"
    ws_cover["C3"] = "Project Name"
    ws_cover["D3"] = "Test Project"
    
    # Content sheet - Varyant 1 (TESTCASE)
    ws1 = wb.create_sheet("Login")
    headers = ["EXISTANCE", "DATE", "APP BUNDLE", "TEST CASE ID", "BR ID", "TR ID",
               "PRIORTY", "CHANNEL", "TESTCASE TYPE", "USER TYPE", 
               "TEST AREA", "TEST SCENARIO", "TESTCASE", "TEST STEPS",
               "PRECONDITION", "TEST DATA", "EXPECTED RESULT"]
    for i, h in enumerate(headers, 1):
        ws1.cell(row=1, column=i, value=h)
    
    # Ã–rnek satÄ±r
    row_data = ["New", "20.05.2024", "Test App", "TC_001", None, None,
                "HIGH", "MOBILE", "Functional", "ALL",
                "Login EkranÄ±", "Login KontrolÃ¼", "Login Test",
                "1- App aÃ§Ä±lÄ±r\n2- Login yapÄ±lÄ±r", None, None,
                "BaÅŸarÄ±lÄ± login beklenir"]
    for i, v in enumerate(row_data, 1):
        ws1.cell(row=2, column=i, value=v)
    
    # Content sheet - Varyant 2 (TEST CASE - boÅŸluklu)
    ws2 = wb.create_sheet("Sepet")
    headers2 = ["EXISTANCE", "DATE", "APP BUNDLE", "TEST CASE ID", "BR ID", "TR ID",
                "PRIORTY", "CHANNEL", "TESTCASE TYPE", "USER TYPE",
                "TEST AREA", "TEST SCENARIO", "TEST CASE", "TEST STEPS",
                "PRECONDITION", "TEST DATA", "EXPECTED RESULT"]
    for i, h in enumerate(headers2, 1):
        ws2.cell(row=1, column=i, value=h)
    
    # DATA sheet (skip edilmeli)
    wb.create_sheet("DATA")
    
    # Revision Changes (skip edilmeli)
    wb.create_sheet("Revision Changes")
    
    # BytesIO'ya kaydet
    from io import BytesIO
    buf = BytesIO()
    wb.save(buf)
    return buf.getvalue()


# tests/test_tc_xlsx_reader.py
class TestTCXlsxReader:
    def test_skip_sheets(self, sample_tc_xlsx):
        """Cover, Revision Changes, DATA sheet'leri atlanmalÄ±."""
        result = read_tc_xlsx(sample_tc_xlsx)
        sheet_names = [s["sheet_name"] for s in result["sheets"]]
        assert "Cover" not in sheet_names
        assert "DATA" not in sheet_names
    
    def test_header_mapping_variant1(self, sample_tc_xlsx):
        """TESTCASE kolonu doÄŸru eÅŸlenmeli."""
        result = read_tc_xlsx(sample_tc_xlsx)
        login_sheet = next(s for s in result["sheets"] if s["sheet_name"] == "Login")
        assert login_sheet["rows"][0].get("testcase_name") == "Login Test"
    
    def test_header_mapping_variant2(self, sample_tc_xlsx):
        """TEST CASE (boÅŸluklu) kolonu da doÄŸru eÅŸlenmeli."""
        result = read_tc_xlsx(sample_tc_xlsx)
        sepet_sheet = next(s for s in result["sheets"] if s["sheet_name"] == "Sepet")
        # Header eÅŸleme testcase_name'e map etmeli
        pass
    
    def test_priority_typo(self, sample_tc_xlsx):
        """PRIORTY (typo) â†’ priority olarak eÅŸlenmeli."""
        result = read_tc_xlsx(sample_tc_xlsx)
        login_sheet = next(s for s in result["sheets"] if s["sheet_name"] == "Login")
        assert login_sheet["rows"][0].get("priority") == "HIGH"
    
    def test_empty_rows_filtered(self, sample_tc_xlsx):
        """Tamamen boÅŸ satÄ±rlar filtrelenmeli."""
        result = read_tc_xlsx(sample_tc_xlsx)
        login_sheet = next(s for s in result["sheets"] if s["sheet_name"] == "Login")
        assert len(login_sheet["rows"]) == 1  # Sadece 1 data satÄ±rÄ±
    
    def test_cover_meta_extraction(self, sample_tc_xlsx):
        """Cover sheet'ten meta bilgiler Ã§Ä±karÄ±lmalÄ±."""
        result = read_tc_xlsx(sample_tc_xlsx)
        assert result["meta"]["project_name"] == "Test Project"
        assert result["meta"]["document_code"] == "LDS-TEST-001"
    
    def test_multiline_test_steps(self, sample_tc_xlsx):
        """Multiline test steps korunmalÄ±."""
        result = read_tc_xlsx(sample_tc_xlsx)
        login_sheet = next(s for s in result["sheets"] if s["sheet_name"] == "Login")
        steps = login_sheet["rows"][0].get("test_steps", "")
        assert "\n" in steps


# tests/test_tc_xlsx_parser.py
class TestTCExcelParser:
    def test_priority_normalization(self):
        """Priority deÄŸerleri normalize edilmeli."""
        parser = TCExcelParser({"meta": {}, "sheets": []})
        assert parser._normalize_priority("CRITICAL") == "CRITICAL"
        assert parser._normalize_priority("critical") == "CRITICAL"
        assert parser._normalize_priority("MED") == "MEDIUM"
    
    def test_tc_id_generation(self):
        """TC ID yoksa otomatik Ã¼retilmeli."""
        parser = TCExcelParser({"meta": {}, "sheets": []})
        assert parser._generate_tc_id("Login", 5) == "TC_AUTO_LOGIN_0005"
    
    def test_summary_calculation(self, sample_tc_xlsx):
        """Summary doÄŸru hesaplanmalÄ±."""
        raw = read_tc_xlsx(sample_tc_xlsx)
        parser = TCExcelParser(raw)
        parsed = parser.parse()
        assert parsed["summary"]["total_test_cases"] >= 1
        assert "MOBILE" in parsed["summary"].get("by_channel", {})
    
    def test_full_parse_pipeline(self, sample_tc_xlsx):
        """UÃ§tan uca parse pipeline Ã§alÄ±ÅŸmalÄ±."""
        raw = read_tc_xlsx(sample_tc_xlsx)
        parser = TCExcelParser(raw)
        result = parser.parse()
        assert result["doc_type"] == "loodos_test_case"
        assert len(result["sheets"]) >= 1
```

---

## Dosya DeÄŸiÅŸiklikleri Ã–zeti

| Dosya | Aksiyon | AÃ§Ä±klama |
|-------|---------|----------|
| `pipeline/tc_xlsx_reader.py` | YENÄ° | XLSX okuma + header eÅŸleme |
| `pipeline/tc_xlsx_parser.py` | YENÄ° | Normalize + JSON dÃ¶nÃ¼ÅŸÃ¼m |
| `pipeline/import_orchestrator.py` | GÃœNCELLE | XLSX tip tespiti ekle |
| `pages/11_Import_Merge.py` | GÃœNCELLE | Multi-file upload, TC preview UI |
| `tests/test_tc_xlsx_reader.py` | YENÄ° | Reader testleri |
| `tests/test_tc_xlsx_parser.py` | YENÄ° | Parser testleri |
| `tests/conftest.py` | GÃœNCELLE | TC XLSX fixture ekle |

## BaÄŸÄ±mlÄ±lÄ±klar

- `openpyxl>=3.1.0` âœ… (requirements.txt'te zaten var olmalÄ±, yoksa ekle)
- Yeni dependency yok.

## Uygulama SÄ±rasÄ±

```
AdÄ±m 1 (Reader) â†’ AdÄ±m 2 (Parser) â†’ AdÄ±m 3 (Orchestrator) â†’ AdÄ±m 4 (UI) â†’ AdÄ±m 5 (DB) â†’ AdÄ±m 6 (Tests)
```

Her adÄ±m baÄŸÄ±msÄ±z olarak commit edilebilir. AdÄ±m 2, AdÄ±m 1'e baÄŸÄ±mlÄ±dÄ±r. AdÄ±m 4, AdÄ±m 3'e baÄŸÄ±mlÄ±dÄ±r.

---

## Claude Code'a Verilecek Prompt

```
docs/ROADMAP_TC_XLSX_IMPORT.md dosyasÄ±nÄ± oku. Bu roadmap'teki 6 adÄ±mÄ± sÄ±rasÄ±yla implement et.

AdÄ±m 1'den baÅŸla. Her adÄ±mÄ± bitirdiÄŸinde bana sÃ¶yle, ben onayladÄ±ktan sonra sonraki adÄ±ma geÃ§.

Ã–nemli notlar:
- Mevcut dosyalarÄ± bozmadan yeni fonksiyonlarÄ± ekle
- Header eÅŸlemede COLUMN_ALIASES dict'ini kullan (typo'lar var: PRIORTY, EXISTANCE)
- TESTCASE ve TEST CASE (boÅŸluklu) iki farklÄ± kolon adÄ±, ikisi de testcase_name'e map edilmeli
- Cover, Revision Changes, DATA sheet'lerini atla
- BoÅŸ satÄ±rlarÄ± filtrele (bazÄ± sheet'ler 1000 satÄ±r ama sadece birkaÃ§Ä± dolu)
- accept_multiple_files=True ile bulk import destekle
- openpyxl kullan (python-docx deÄŸil)
```
